import streamlit as st
import pandas as pd


class ML_prepare_viewset:
    def __init__(self):
        pass

    def tabs_manager(self):
        st.session_state.current_page = "ML Preparations"
        st.title("Machine Learning Preparations")
        st.markdown("---")
        menu = st.tabs(
            [
                "üåê‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•",
                "üó≥Ô∏è‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model SVM",
                "üó≥Ô∏è‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model RandomForest",
            ]
        )
        with menu[0]:
            self.dataset_preparation()
        with menu[1]:
            self.svm_model_training()
            st.markdown("""---""")
            self.load_model_and_scaler()
        with menu[2]:
            self.rf_model_training()
            st.markdown("""---""")
            self.load_model_and_scaler()

    def dataset_preparation(self):
        st.header("üîç Data Preparation")
        st.markdown(
            """
            ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô models ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡∏Ñ‡πâ‡∏ô‡∏´‡∏≤ datasets ‡πÉ‡∏ô [<span style='color:blue; text-decoration:none'>Kaggle</span>](https://www.kaggle.com/) ‡πÅ‡∏•‡∏∞ [<span style='color:blue; text-decoration:none'>UCI</span>](https://archive.ics.uci.edu/) ‡∏ú‡∏°‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            "[<span style='color:orange; text-decoration:none; font-weight:bold'>Census Income</span>](https://archive.ics.uci.edu/dataset/2/adult)"
            """,
            unsafe_allow_html=True,
        )
        with st.expander("üìä ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Dataset Details)"):
            col1, col2 = st.columns(2)
            with col1:
                st.write("**‡πÅ‡∏´‡∏•‡πà‡∏á‡∏ó‡∏µ‡πà‡∏°‡∏≤:** UCI Machine Learning Repository")
                st.write("**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á:** 48,842 instances")
            with col2:
                st.write("**‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞:** 14 attributes")
                st.write("**‡πÄ‡∏õ‡πâ‡∏≤‡∏´‡∏°‡∏≤‡∏¢:** ‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤/‡∏ô‡πâ‡∏≠‡∏¢‡∏Å‡∏ß‡πà‡∏≤ $50K")

        st.header("ü§ñ Model Selection")
        st.markdown(
            "‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÉ‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• **SVM ‡πÅ‡∏•‡∏∞ RandomForestClassifier** ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡πÄ‡∏á‡∏¥‡∏ô‡πÄ‡∏î‡∏∑‡∏≠‡∏ô‡∏à‡∏≤‡∏Å input ‡∏ó‡∏µ‡πà‡∏£‡∏±‡∏ö‡∏°‡∏≤‡∏ß‡πà‡∏≤‡∏à‡∏∞‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50k ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà"
        )

        st.header("üìã ‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Census Income")

        feature_data = {
            "‡∏ä‡∏∑‡πà‡∏≠": [
                "‡∏≠‡∏≤‡∏¢‡∏∏ (age)",
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Å‡∏≤‡∏£‡∏à‡πâ‡∏≤‡∏á‡∏á‡∏≤‡∏ô (workclass)",
                "‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£ (fnlwgt)",
                "‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (education)",
                "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤-‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç (education-num)",
                "‡∏™‡∏ñ‡∏≤‡∏ô‡∏†‡∏≤‡∏û‡∏™‡∏°‡∏£‡∏™ (marital-status)",
                "‡∏≠‡∏≤‡∏ä‡∏µ‡∏û (occupation)",
                "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå (relationship)",
                "‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏ä‡∏≤‡∏ï‡∏¥ (race)",
                "‡πÄ‡∏û‡∏® (sex)",
                "‡∏Å‡∏≥‡πÑ‡∏£‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏ô (capital-gain)",
                "‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏à‡∏≤‡∏Å‡∏ó‡∏∏‡∏ô (capital-loss)",
                "‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå (hours-per-week)",
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î (native-country)",
            ],
            "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó": [
                "Continuous",
                "Categorical",
                "Continuous",
                "Categorical",
                "Continuous",
                "Categorical",
                "Categorical",
                "Categorical",
                "Categorical",
                "Categorical",
                "Continuous",
                "Continuous",
                "Continuous",
                "Categorical",
            ],
            "‡∏£‡∏≤‡∏¢‡∏•‡∏∞‡πÄ‡∏≠‡∏µ‡∏¢‡∏î": [
                "‡∏≠‡∏≤‡∏¢‡∏∏‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏õ‡∏µ",
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏Ç‡∏≠‡∏á‡∏ô‡∏≤‡∏¢‡∏à‡πâ‡∏≤‡∏á‡∏´‡∏£‡∏∑‡∏≠‡∏Å‡∏≤‡∏£‡∏à‡πâ‡∏≤‡∏á‡∏á‡∏≤‡∏ô",
                "‡∏ô‡πâ‡∏≥‡∏´‡∏ô‡∏±‡∏Å‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ó‡∏µ‡πà‡∏™‡∏≥‡∏£‡∏ß‡∏à‡πÇ‡∏î‡∏¢‡∏™‡∏≥‡∏°‡∏∞‡πÇ‡∏ô‡∏õ‡∏£‡∏∞‡∏ä‡∏≤‡∏Å‡∏£ ‡πÅ‡∏™‡∏î‡∏á‡∏ñ‡∏∂‡∏á‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏Ñ‡∏ô‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Ñ‡∏∏‡∏ì‡∏•‡∏±‡∏Å‡∏©‡∏ì‡∏∞‡∏Ñ‡∏•‡πâ‡∏≤‡∏¢‡∏Ñ‡∏•‡∏∂‡∏á‡∏Å‡∏±‡∏ô",
                "‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î‡∏ó‡∏µ‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à",
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ó‡∏µ‡πà‡πÅ‡∏ó‡∏ô‡∏£‡∏∞‡∏î‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏®‡∏∂‡∏Å‡∏©‡∏≤ (1-16)",
                "‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏™‡∏°‡∏£‡∏™‡∏õ‡∏±‡∏à‡∏à‡∏∏‡∏ö‡∏±‡∏ô",
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏†‡∏ó‡∏á‡∏≤‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏≠‡∏≤‡∏ä‡∏µ‡∏û‡∏ó‡∏µ‡πà‡∏ó‡∏≥",
                "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏±‡∏°‡∏û‡∏±‡∏ô‡∏ò‡πå‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß",
                "‡∏Å‡∏•‡∏∏‡πà‡∏°‡πÄ‡∏ä‡∏∑‡πâ‡∏≠‡∏ä‡∏≤‡∏ï‡∏¥‡∏ó‡∏µ‡πà‡∏£‡∏∞‡∏ö‡∏∏",
                "‡πÄ‡∏û‡∏®‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•",
                "‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≤‡∏¢‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏™‡∏¥‡∏ô",
                "‡∏Å‡∏≤‡∏£‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô‡∏à‡∏≤‡∏Å‡∏Å‡∏≤‡∏£‡∏•‡∏á‡∏ó‡∏∏‡∏ô‡∏´‡∏£‡∏∑‡∏≠‡∏Ç‡∏≤‡∏¢‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏™‡∏¥‡∏ô",
                "‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡∏ä‡∏±‡πà‡∏ß‡πÇ‡∏°‡∏á‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏ï‡πà‡∏≠‡∏™‡∏±‡∏õ‡∏î‡∏≤‡∏´‡πå",
                "‡∏õ‡∏£‡∏∞‡πÄ‡∏ó‡∏®‡∏ó‡∏µ‡πà‡πÄ‡∏Å‡∏¥‡∏î‡∏´‡∏£‡∏∑‡∏≠‡∏°‡∏µ‡∏™‡∏±‡∏ç‡∏ä‡∏≤‡∏ï‡∏¥",
            ],
            "‡∏Ñ‡πà‡∏≤‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡πÑ‡∏õ‡πÑ‡∏î‡πâ": [
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Continuous)",
                "‡πÄ‡∏≠‡∏Å‡∏ä‡∏ô, ‡∏£‡∏±‡∏ö‡∏à‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡πÄ‡∏≠‡∏á, ‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡∏Å‡∏•‡∏≤‡∏á, ‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡∏ó‡πâ‡∏≠‡∏á‡∏ñ‡∏¥‡πà‡∏ô, ‡∏£‡∏±‡∏ê‡∏ö‡∏≤‡∏•‡∏°‡∏•‡∏£‡∏±‡∏ê, ‡πÑ‡∏°‡πà‡πÑ‡∏î‡πâ‡∏£‡∏±‡∏ö‡∏Ñ‡πà‡∏≤‡∏à‡πâ‡∏≤‡∏á, ‡πÑ‡∏°‡πà‡πÄ‡∏Ñ‡∏¢‡∏ó‡∏≥‡∏á‡∏≤‡∏ô",
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á",
                "‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡∏ï‡∏£‡∏µ, ‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏•‡∏±‡∏¢, ‡∏°‡∏±‡∏ò‡∏¢‡∏°‡∏®‡∏∂‡∏Å‡∏©‡∏≤, ‡∏ö‡∏±‡∏ì‡∏ë‡∏¥‡∏ï‡∏ß‡∏¥‡∏ä‡∏≤‡∏ä‡∏µ‡∏û, ‡∏≠‡∏ô‡∏∏‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤, ‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÇ‡∏ó, ‡∏õ‡∏£‡∏¥‡∏ç‡∏ç‡∏≤‡πÄ‡∏≠‡∏Å, ‡∏Ø‡∏•‡∏Ø",
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Continuous)",
                "‡πÅ‡∏ï‡πà‡∏á‡∏á‡∏≤‡∏ô, ‡∏´‡∏¢‡πà‡∏≤‡∏£‡πâ‡∏≤‡∏á, ‡πÇ‡∏™‡∏î, ‡πÅ‡∏¢‡∏Å‡∏Å‡∏±‡∏ô‡∏≠‡∏¢‡∏π‡πà, ‡∏´‡∏°‡πâ‡∏≤‡∏¢, ‡∏Ñ‡∏π‡πà‡∏™‡∏°‡∏£‡∏™‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà",
                "‡∏™‡∏ô‡∏±‡∏ö‡∏™‡∏ô‡∏∏‡∏ô‡∏î‡πâ‡∏≤‡∏ô‡πÄ‡∏ó‡∏Ñ‡∏ô‡∏¥‡∏Ñ, ‡∏á‡∏≤‡∏ô‡∏ä‡πà‡∏≤‡∏á, ‡∏á‡∏≤‡∏ô‡∏ö‡∏£‡∏¥‡∏Å‡∏≤‡∏£, ‡∏Ç‡∏≤‡∏¢, ‡∏ú‡∏π‡πâ‡∏ö‡∏£‡∏¥‡∏´‡∏≤‡∏£, ‡∏ú‡∏π‡πâ‡πÄ‡∏ä‡∏µ‡πà‡∏¢‡∏ß‡∏ä‡∏≤‡∏ç, ‡πÄ‡∏™‡∏°‡∏µ‡∏¢‡∏ô, ‡πÄ‡∏Å‡∏©‡∏ï‡∏£‡∏Å‡∏£‡∏£‡∏°, ‡∏Ø‡∏•‡∏Ø",
                "‡∏†‡∏£‡∏£‡∏¢‡∏≤, ‡∏ö‡∏∏‡∏ï‡∏£, ‡∏™‡∏≤‡∏°‡∏µ, ‡πÑ‡∏°‡πà‡∏≠‡∏¢‡∏π‡πà‡πÉ‡∏ô‡∏Ñ‡∏£‡∏≠‡∏ö‡∏Ñ‡∏£‡∏±‡∏ß, ‡∏ç‡∏≤‡∏ï‡∏¥‡∏≠‡∏∑‡πà‡∏ô‡πÜ, ‡πÇ‡∏™‡∏î",
                "‡πÄ‡∏≠‡πÄ‡∏ä‡∏µ‡∏¢-‡∏´‡∏°‡∏π‡πà‡πÄ‡∏Å‡∏≤‡∏∞‡πÅ‡∏õ‡∏ã‡∏¥‡∏ü‡∏¥‡∏Å, ‡∏≠‡πÄ‡∏°‡∏£‡∏¥‡∏Å‡∏±‡∏ô‡∏≠‡∏¥‡∏ô‡πÄ‡∏î‡∏µ‡∏¢‡∏ô-‡πÄ‡∏≠‡∏™‡∏Å‡∏¥‡πÇ‡∏°, ‡∏≠‡∏∑‡πà‡∏ô‡πÜ",
                "‡∏´‡∏ç‡∏¥‡∏á, ‡∏ä‡∏≤‡∏¢",
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Continuous)",
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Continuous)",
                "‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á (Continuous)",
                "‡∏™‡∏´‡∏£‡∏±‡∏ê‡∏≠‡πÄ‡∏°‡∏£‡∏¥‡∏Å‡∏≤, ‡∏Å‡∏±‡∏°‡∏û‡∏π‡∏ä‡∏≤, ‡∏≠‡∏±‡∏á‡∏Å‡∏§‡∏©, ‡πÄ‡∏õ‡∏≠‡∏£‡πå‡πÇ‡∏ï‡∏£‡∏¥‡πÇ‡∏Å, ‡πÅ‡∏Ñ‡∏ô‡∏≤‡∏î‡∏≤, ‡πÄ‡∏¢‡∏≠‡∏£‡∏°‡∏ô‡∏µ, ‡∏≠‡∏¥‡∏ô‡πÄ‡∏î‡∏µ‡∏¢, ‡∏ç‡∏µ‡πà‡∏õ‡∏∏‡πà‡∏ô, ‡∏à‡∏µ‡∏ô, ‡πÑ‡∏ó‡∏¢, ‡∏Ø‡∏•‡∏Ø",
            ],
        }

        df_features = pd.DataFrame(feature_data)
        st.dataframe(df_features, use_container_width=True, height=550)

        st.info("""
        **‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏:** 
        * ‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏î‡πâ‡∏≤‡∏ô‡∏ö‡∏ô‡∏ñ‡∏π‡∏Å‡πÅ‡∏õ‡∏•‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå `adult.names` ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÉ‡∏´‡πâ‡∏á‡πà‡∏≤‡∏¢‡∏ï‡πà‡∏≠‡∏Å‡∏≤‡∏£‡πÄ‡∏Ç‡πâ‡∏≤‡πÉ‡∏à‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡πÅ‡∏ï‡πà‡∏•‡∏∞ Features
        * ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏≥‡∏ô‡∏≤‡∏¢‡∏ß‡πà‡∏≤‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ‡∏Ç‡∏≠‡∏á‡∏ö‡∏∏‡∏Ñ‡∏Ñ‡∏•‡∏à‡∏∞‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 50,000 ‡∏î‡∏≠‡∏•‡∏•‡∏≤‡∏£‡πå‡∏ï‡πà‡∏≠‡∏õ‡∏µ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
        * ‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô `adult.data` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô‡πÇ‡∏°‡πÄ‡∏î‡∏• ‡πÅ‡∏•‡∏∞ `adult.test` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏î‡∏™‡∏≠‡∏ö‡πÇ‡∏°‡πÄ‡∏î‡∏•
        * ‡πÇ‡∏°‡πÄ‡∏î‡∏• SVM ‡πÅ‡∏•‡∏∞ RandomForestClassifier ‡∏à‡∏∞‡∏ñ‡∏π‡∏Å‡πÄ‡∏ó‡∏£‡∏ô‡∏î‡πâ‡∏ß‡∏¢‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ä‡∏∏‡∏î‡∏ô‡∏µ‡πâ
        """)

        st.header("‚öôÔ∏è ‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Data Preparation Process)")

        code_tabs = st.tabs(
            ["1Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "2Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•", "3Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏≠‡πà‡∏≤‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏û‡∏£‡πâ‡∏≠‡∏° Label"]
        )
        st.markdown(
            """
        <style>
            .stTabs [data-baseweb="tab"] {
                font-size: 28px; 
                font-weight: bold;
            }
            
            .stTabs [data-baseweb="tab-list"] {
                gap: 1.5rem;
            }
        </style>
        """,
            unsafe_allow_html=True,
        )
        with code_tabs[0]:
            st.code(
                """
                    import pandas as pd
                    df = pd.read_csv('../data/income/adult.data')
                    df.shape
                """
            )

        with code_tabs[1]:
            st.code("""
                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏ö‡∏∑‡πâ‡∏≠‡∏á‡∏ï‡πâ‡∏ô
                    df.info()
                    df.head()
                    #Output:
                    <class 'pandas.core.frame.DataFrame'>
                    RangeIndex: 32560 entries, 0 to 32559
                    Data columns (total 15 columns):
                    #   Column          Non-Null Count  Dtype 
                    ---  ------          --------------  ----- 
                    0   39              32560 non-null  int64 
                    1    State-gov      32560 non-null  object
                    2    77516          32560 non-null  int64 
                    3    Bachelors      32560 non-null  object
                    4    13             32560 non-null  int64 
                    5    Never-married  32560 non-null  object
                    6    Adm-clerical   32560 non-null  object
                    7    Not-in-family  32560 non-null  object
                    8    White          32560 non-null  object
                    9    Male           32560 non-null  object
                    10   2174           32560 non-null  int64 
                    11   0              32560 non-null  int64 
                    12   40             32560 non-null  int64 
                    13   United-States  32560 non-null  object
                    14   <=50K          32560 non-null  object
                    dtypes: int64(6), object(9)
                    memory usage: 3.7+ MB
                """)

        with code_tabs[2]:
            st.code("""
                    # ‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏Å‡πà‡∏≠‡∏ô‡∏´‡∏ô‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ feature label (‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÑ‡∏î‡πâ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠ column) ‡∏à‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡∏°‡πà‡πÇ‡∏î‡∏¢‡πÉ‡∏™‡πà feature label ‡∏à‡∏≤‡∏Å adult.name
                    def read_adult_names_file(file_path):
                        with open(file_path, 'r') as file:
                            content = file.read()
                        
                        feature_section = content.split('>50K, <=50K.')[1].strip()
                        
                        features = []
                        
                        for line in feature_section.split('\\n'):
                            if line.strip():
                                parts = line.split(': ')
                                if len(parts) == 2:
                                    feature_name = parts[0].strip()
                                    features.append(feature_name)
                        
                        features.append('income')
                        
                        return features

                    column_names = read_adult_names_file('../data/income/adult.names')
                    df = pd.read_csv('../data/income/adult.data', 
                                    header=None,  
                                    names=column_names, 
                                    sep=', ',
                                    engine='python')
                    df.head()
        """)
        second_code_tabs = st.tabs(
            [
                "4Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏≠‡∏µ‡∏Å‡∏Ñ‡∏£‡∏±‡πâ‡∏á",
                "5Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏Ñ‡∏ß‡∏≤‡∏°‡∏™‡∏∞‡∏≠‡∏≤‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• (Cleaning datasets)",
                "6Ô∏è‚É£ ‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏´‡πâ‡πÄ‡∏õ‡πá‡∏ô numeric ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î",
            ]
        )

        with second_code_tabs[0]:
            st.code("""
                    # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏°‡∏µ `null` ‡∏´‡∏£‡∏∑‡∏≠ `NaN` ‡∏°‡∏±‡πâ‡∏¢
                    df.isnull().sum()
                    # Output:
                    age               0
                    workclass         0
                    fnlwgt            0
                    education         0
                    education-num     0
                    marital-status    0
                    occupation        0
                    relationship      0
                    race              0
                    sex               0
                    capital-gain      0
                    capital-loss      0
                    hours-per-week    0
                    native-country    0
                    income            0
                    dtype: int64
                    \n
                    # df.dropna(inplace = True) ‡∏´‡∏≤‡∏Å‡∏°‡∏µ
                    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ä‡πá‡∏Ñ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏ï‡πà‡∏•‡∏∞ column ‡∏à‡∏∞‡∏™‡∏±‡∏á‡πÄ‡∏Å‡∏ï‡πÑ‡∏î‡πâ‡∏ß‡πà‡∏≤‡∏°‡∏µ '?' ‡∏õ‡∏ô‡∏°‡∏≤‡πÉ‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                    for column in df.columns:
                        j = df[column].value_counts(dropna=False)
                        print(column,':',j)
                        print('----------------------------------------')
                    # Output:
                    age : age
                    36    898
                    31    888
                    34    886
                    23    877
                    35    876
                        ... 
                    83      6
                    88      3
                    85      3
                    86      1
                    87      1
                    Name: count, Length: 73, dtype: int64
                    ----------------------------------------
                    workclass : workclass
                    Private             22696
                    Self-emp-not-inc     2541
                    Local-gov            2093
                    ?                    1836
                    State-gov            1298
                    Self-emp-inc         1116
                    Federal-gov           960
                    Without-pay            14
                    Never-worked            7
                    Name: count, dtype: int64
                    ...
                    <=50K    24720
                    >50K      7841
                    Name: count, dtype: int64
                    ----------------------------------------
            """)
        with second_code_tabs[1]:
            st.code("""
                    # ‡∏î‡∏£‡∏≠‡∏õ row ‡∏ó‡∏µ‡πà‡∏°‡∏µ '?' ‡∏≠‡∏¢‡∏π‡πà
                    for column in df.columns:
                        df.drop(df[df[column] == '?'].index, inplace=True)  
                    
            """)
        with second_code_tabs[2]:
            st.code("""
                    # ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÇ‡∏î‡∏¢‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÄ‡∏õ‡πá‡∏ô‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏° (string) ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
                    # ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏ó‡∏µ‡πà‡∏à‡∏∞‡∏ó‡∏≥‡πÉ‡∏´‡πâ‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ô‡∏≥‡∏°‡∏≤‡πÄ‡∏ó‡∏£‡∏ô AI ‡πÑ‡∏î‡πâ
                    def map_data(x):
                        convert = x.unique()
                        return x.map(dict(zip(convert, range(1,len(convert) + 1))))
                    for column in df.columns:
                        if df[column].dtype == 'object':
                            df[column] = map_data(df[column])
                    df.astype(int)
            """)
        st.info("""
                **‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å dataset ‡∏ñ‡∏π‡∏Å‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏õ‡πá‡∏ô 2 ‡πÑ‡∏ü‡∏•‡πå**
                * `adult.data` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô
                * `adult.test` ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå\n
                """)
        st.subheader("üéØ‡∏à‡∏±‡∏î‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏à‡∏∞‡πÉ‡∏ä‡πâ‡πÄ‡∏ó‡∏£‡∏ô‡πÅ‡∏•‡∏∞‡∏ó‡∏î‡∏™‡∏≠‡∏ö")
        st.markdown("---")
        st.code("""
                df_test = pd.read_csv('../data/income/adult.test',
                      header=None,  
                      names=column_names, 
                      sep=', ',
                      engine='python')
                df_test.isnull().sum()
                #Output
                age               0
                workclass         1
                fnlwgt            1
                education         1
                education-num     1
                marital-status    1
                occupation        1
                relationship      1
                race              1
                sex               1
                capital-gain      1
                capital-loss      1
                hours-per-week    1
                native-country    1
                income            1
                dtype: int64
                # ‡πÄ‡∏ô‡∏∑‡πâ‡πà‡∏≠‡∏á‡∏à‡∏≤‡∏Å‡∏ä‡∏∏‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• test ‡∏°‡∏µ null value ‡∏ó‡∏≥‡∏Å‡∏≤‡∏£‡∏î‡∏£‡∏≠‡∏õ‡∏ó‡∏¥‡πâ‡∏á
                df_test.dropna(inplace=True)

                for column in df_test.columns:
                    df_test.drop(df_test[df_test[column] == '?'].index, inplace=True)  
                for column in df_test.columns:
                    if df_test[column].dtype == 'object':
                        df_test[column] = map_data(df_test[column])
                df_test.astype(int)

                X_train = df.drop('income', axis=1)
                y_train = df['income']

                X_test = df_test.drop('income',axis=1)
                y_test = df['income']
        """)
        st.markdown("---")
        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°")

    def svm_model_training(self):
        st.header("üåü ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model K-Mean Clustering")
        st.markdown("---")
        st.subheader("ü™õCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model K-Mean Clustering")
        st.markdown("---")
        st.subheader("üñ•Ô∏èImport Library")
        st.code("""
                from sklearn.svm import SVC
                from sklearn.preprocessing import StandardScaler
                from sklearn.metrics import classification_report, accuracy_score
                import joblib
            
        """)
        st.subheader("üñ•Ô∏èCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        st.code("""
                scaler = StandardScaler()  
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
        """)
        st.subheader("üõ†Ô∏è‡∏™‡∏£‡πâ‡∏≤‡∏á Model SVM ‡∏î‡πâ‡∏ß‡∏¢ sklearn ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ hyperparameter tuning")
        st.markdown("---")
        st.code("""
                svm = SVC(kernel='rbf',  
                        C=1.0,         
                        gamma='scale',
                        probability=True,
                        random_state=42)

                if len(y_train.shape) > 1: # ‡∏ñ‡πâ‡∏≤ y_train ‡∏°‡∏µ shape ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1
                    y_train = y_train.flatten()
                if len(y_test.shape) > 1: # ‡∏ñ‡πâ‡∏≤ y_test ‡∏°‡∏µ shape ‡∏°‡∏≤‡∏Å‡∏Å‡∏ß‡πà‡∏≤ 1
                    y_test = y_test.flatten()
                """)
        st.markdown("---")
        st.subheader(
            "üñ•Ô∏èCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model SVM ‡πÅ‡∏•‡∏∞ ‚úçüèª‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Model SVM ‡πÅ‡∏•‡∏∞ Save model"
        )
        st.code("""
                svm.fit(X_train_scaled, y_train)
                accuracy = accuracy_score(y_test, y_pred)
                print(f"Test accuracy: {accuracy:.4f}")
                print("\\nClassification Report:")
                print(classification_report(y_test, y_pred))
                probabilities = svm.predict_proba(X_test_scaled)
                joblib.dump(svm, '../exported_models/svm/svm_income_model.pkl')
                joblib.dump(scaler, '../exported_models/svm/svm_income_scaler.pkl')
                """)
        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model SVM ")

    def rf_model_training(self):
        st.header("üåü ‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model RandomForestClassifier")
        st.markdown("---")
        st.subheader("ü™õCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô RandomForestClassifier")
        st.markdown("---")
        st.subheader("üñ•Ô∏èImport Library")
        st.code("""
                from sklearn.preprocessing import StandardScaler
                from sklearn.ensemble import RandomForestClassifier
                from sklearn.metrics import classification_report, accuracy_score
                import joblib
            
        """)
        st.subheader("üñ•Ô∏èCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•")
        st.code("""
                scaler = StandardScaler()
                X_train_scaled = scaler.fit_transform(X_train)
                X_test_scaled = scaler.transform(X_test)
                if len(y_train.shape) > 1:
                    y_train = y_train.flatten()
                if len(y_test.shape) > 1: 
                    y_test = y_test.flatten()
        """)
        st.subheader("üõ†Ô∏è‡∏™‡∏£‡πâ‡∏≤‡∏á Model RF ‡∏î‡πâ‡∏ß‡∏¢ sklearn ‡πÅ‡∏•‡∏∞‡∏ó‡∏≥‡∏Å‡∏≤‡∏£ hyperparameter tuning")
        st.markdown("---")
        st.code("""
                model = RandomForestClassifier(n_estimators=100, random_state=50, class_weight="balanced")
                """)
        st.markdown("---")
        st.subheader(
            "üñ•Ô∏èCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model RF ‡πÅ‡∏•‡∏∞ ‚úçüèª‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô Model RF ‡πÅ‡∏•‡∏∞ Save model"
        )
        st.code("""
                    model.fit(X_train_scaled, y_train)
                    rfc_result_trained = model.predict(X_test_scaled)
                    accuracy = accuracy_score(y_test, rfc_result_trained)
                    print(f"Test accuracy: {accuracy:.4f}")
                    print("\\nClassification Report:")
                    print(classification_report(y_test, rfc_result_trained))
                    joblib.dump(model, '../exported_models/random_forest/rf_income_model.pkl')
                    joblib.dump(scaler,  '../exported_models/random_forest/_income_scaler.pkl') 

                """)
        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏£‡∏ô Model RandomForestClassifier")

    def load_model_and_scaler(self):
        st.header("üåü ‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model ‡πÅ‡∏•‡∏∞ Scaler ‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.markdown("---")
        st.subheader("üñ•Ô∏èCode ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model ‡πÅ‡∏•‡∏∞ Scaler")
        st.code("""
                def load_model(model_path, scaler_path=None):
                    try:
                        # Try loading model with joblib first
                        try:
                            model = joblib.load(model_path)
                        except Exception as e1:
                            st.warning(f"Could not load model with joblib: {str(e1)}")
                            with open(model_path, "rb") as f:
                                model = pickle.load(f)

                        # Load scaler if provided
                        scaler = None
                        if scaler_path:
                            if not os.path.exists(scaler_path):
                                st.error(f"Scaler file not found at: {scaler_path}")
                            else:
                                try:
                                    scaler = joblib.load(scaler_path)
                                except Exception as e2:
                                    st.warning(f"Could not load scaler with joblib: {str(e2)}")
                                    with open(scaler_path, "rb") as f:
                                        scaler = pickle.load(f)

                        return model, scaler

                    except Exception as e:
                        st.error(f"Error loading model: {str(e)}")
                        return None, None

                """)
        st.markdown("---")
        st.subheader("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡∏ô‡∏≥‡πÑ‡∏õ‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        st.code("""
                class ML_implement_viewset:
                    def __init__(self):
                        # Load models
                        self.svm_model, self.svm_scaler = load_model(
                            "exported_models/svm/svm_income_model.pkl",
                            "exported_models/svm/svm_income_scaler.pkl",
                        )
                        self.rf_model, self.rf_scaler = load_model(
                            "exported_models/rf/rf_income_model.pkl",
                            "exported_models/rf/rf_income_scaler.pkl",
                        )
                        ...
                """)
        st.subheader("üéâüéâüéâ ‡πÄ‡∏£‡∏µ‡∏¢‡∏ö‡∏£‡πâ‡∏≠‡∏¢‡∏Ñ‡∏£‡∏±‡∏ö‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡∏±‡πâ‡∏ô‡∏ï‡∏≠‡∏ô‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î Model ‡πÅ‡∏•‡∏∞ Scaler")
        st.markdown("---")
